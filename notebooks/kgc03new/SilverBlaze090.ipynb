{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b2dca8",
   "metadata": {
    "hide_input": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "# ========== python ==========\n",
    "import os\n",
    "from pathlib import Path\n",
    "from logging import Logger\n",
    "from typing import List, Dict, Tuple, Optional, Union, Callable, Final, Literal, get_args\n",
    "from operator import itemgetter, attrgetter\n",
    "import itertools\n",
    "from IPython import display\n",
    "\n",
    "from utils.setup import setup_logger, get_device\n",
    "from const.const_values import PROJECT_DIR\n",
    "\n",
    "os.chdir(PROJECT_DIR)\n",
    "logger: Logger = setup_logger(__name__, f'{PROJECT_DIR}/log/jupyter_run.log')\n",
    "device = get_device(device_name='cpu', logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d6167a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# jupyter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Machine learning\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import optuna\n",
    "# torch\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "# torch ignite\n",
    "from ignite.engine import Engine\n",
    "from ignite.handlers import Checkpoint\n",
    "# My items\n",
    "from models.datasets.data_helper import MyDataHelperForStory, MyDataLoaderHelper, DefaultTokens\n",
    "from models.datasets.datasets_for_story import StoryTriple\n",
    "# My utils\n",
    "from utils.setup import load_param\n",
    "from utils.torch import load_model, torch_fix_seed\n",
    "# main function\n",
    "from run_for_KGC import main_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc4b193",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from const.const_values import CPU, MODEL\n",
    "from models.KGModel.kg_model import HEAD, RELATION, TAIL\n",
    "from utils.torch_ignite import TRAINER, EVALUATOR\n",
    "from const.const_values import DATASETS, DATA_HELPER, DATA_LOADERS, TRAIN_RETURNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2ac743",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEED: Final[int] = 42\n",
    "args_path = f'{PROJECT_DIR}/models/kgc03a/SilverBlaze090/param.pkl'\n",
    "model_path = f'{PROJECT_DIR}/models/kgc03a/SilverBlaze090/model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac36f2a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "args = load_param(args_path)\n",
    "\n",
    "# args.pre_train = True\n",
    "args.logger = logger\n",
    "args.device = device\n",
    "args.batch_size = 1\n",
    "args.pre_train=False\n",
    "args.init_embedding_using_bert = False\n",
    "args.model_path = model_path\n",
    "args.only_load_trainer_evaluator = True\n",
    "args.old_data = 1\n",
    "\n",
    "del args.optuna_file, args.device_name, args.pid, args.study_name, args.n_trials\n",
    "logger.info(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faf7204",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch_fix_seed(seed=SEED)\n",
    "return_dict = main_function(args, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6300cb9",
   "metadata": {
    "hide_input": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = return_dict[MODEL]\n",
    "\n",
    "dataset_train: StoryTriple = return_dict[DATASETS][0]\n",
    "triple: torch.Tensor = dataset_train.triple\n",
    "data_helper: MyDataHelperForStory = return_dict[DATA_HELPER]\n",
    "evaluator: Checkpoint = return_dict[TRAIN_RETURNS][EVALUATOR]\n",
    "\n",
    "load_model(model, args.model_path, device)\n",
    "model.eval()\n",
    "\n",
    "entities, relations = data_helper.processed_entities, data_helper.processed_relations\n",
    "d_e, d_r = {e: i for i, e in enumerate(entities)}, {r: i for i, r in enumerate(relations)}\n",
    "\n",
    "triple_df = pd.DataFrame([(entities[_t[0]], relations[_t[1]], entities[_t[2]]) for _t in triple], columns=[HEAD, RELATION, TAIL])\n",
    "story_entities = triple_df[HEAD].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0a93c2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "triple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3573be3a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def extract(_model, target, inputs):\n",
    "    features = None\n",
    "\n",
    "    def forward_hook(_module, _inputs, _):\n",
    "        nonlocal features\n",
    "        x, _, _ = _inputs\n",
    "        outputs = _module.forward(x, x, x, need_weights=True)[1]\n",
    "        features = outputs.detach().clone()\n",
    "\n",
    "    handle = target.register_forward_hook(forward_hook)\n",
    "\n",
    "    _model.eval()\n",
    "    _model(inputs, torch.LongTensor([[]]), torch.LongTensor([[]]), torch.LongTensor([[]]))\n",
    "\n",
    "    handle.remove()\n",
    "\n",
    "    return features\n",
    "\n",
    "def get_attention(input_):\n",
    "    assert len(input_) == 1\n",
    "    features = extract(model, model.transformer.layers[-1].self_attn, input_)[0]\n",
    "    df_attention = pd.DataFrame([[entities[h], relations[r], entities[t]]+[features[j, i].item() for j in range(len(features))] for i, (h, r, t) in enumerate(input_[0])])\n",
    "    df_attention.columns=[HEAD, RELATION, TAIL] + [f'atten_from{i}' for i in range(len(df_attention.columns)-3)]\n",
    "    return df_attention\n",
    "\n",
    "def show_attension_heatmap(df_attention):\n",
    "    sns.heatmap(df_attention.iloc[:,3:])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e12755f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MASK_E = DefaultTokens.MASK_E\n",
    "KILL = 'word.predicate:kill'\n",
    "\n",
    "TAKE = 'word.predicate:take'\n",
    "BRING = 'word.predicate:bring'\n",
    "DIE = 'word.predicate:die'\n",
    "HIDE = 'word.predicate:hide'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8832fe9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bos_triple = [d_e[DefaultTokens.BOS_E], d_r[DefaultTokens.BOS_R],d_e[DefaultTokens.BOS_E]]\n",
    "mask_e_id = d_e[DefaultTokens.MASK_E]\n",
    "Holmes_id =d_e['AllTitle:Holmes']\n",
    "\n",
    "def make_ranking(from_story_name, to_story_name, predicate_, whom_, subject_, why_, what_, where_):\n",
    "    if not (from_story_name is None and to_story_name is None):\n",
    "        _start_index = story_entities.index(from_story_name)-1 \n",
    "        _end_index = len(story_entities) - story_entities[::-1].index(to_story_name)\n",
    "    else: \n",
    "        _start_index = 0\n",
    "        _end_index = 0\n",
    "    question_ = torch.tensor(\n",
    "        [\n",
    "            bos_triple, \n",
    "            [mask_e_id, d_r['kgc:infoSource'],     Holmes_id      ],\n",
    "            [mask_e_id, d_r['kgc:hasPredicate'],   d_e[predicate_]],\n",
    "            [mask_e_id, d_r['kgc:whom'],           d_e[whom_     ]],\n",
    "            [mask_e_id, d_r['kgc:subject'],        d_e[subject_  ]],\n",
    "            [mask_e_id, d_r['kgc:why'],            d_e[why_      ]],\n",
    "            [mask_e_id, d_r['kgc:what'],           d_e[what_     ]],\n",
    "            [mask_e_id, d_r['kgc:where'],          d_e[where_    ]],\n",
    "        ]\n",
    "    )\n",
    "    mask_ = torch.zeros_like(question_, dtype=torch.bool) # not mask all position\n",
    "    mask_[1:, 0] = True                                   # where head position without bos token\n",
    "    mask_[1:, 2] = True                                   # where tail position without bos token\n",
    "\n",
    "    last_triples = triple[_start_index: _end_index]\n",
    "\n",
    "    questions = torch.cat([last_triples, question_], dim=0).unsqueeze(0)\n",
    "    masks = torch.cat([torch.zeros_like(last_triples), mask_], dim=0).to(torch.bool).transpose(1,0).unsqueeze(0)\n",
    "\n",
    "    data_list = []\n",
    "    with torch.no_grad():\n",
    "        _, (story_pred, relation_pred, entity_pred) = model(questions, masks[:,0], masks[:,1], masks[:,2])\n",
    "        sorted_ = torch.argsort(entity_pred, dim=1, descending=True)\n",
    "        for i in range(sorted_.shape[1]):\n",
    "            ans_= sorted_[:, i]\n",
    "            info_source_, predicate_pred, whom_pred, subject_pred, why_pred, what_pred, where_pred = ans_\n",
    "            data_list.append([entities[predicate_pred], entities[whom_pred], entities[subject_pred], entities[why_pred], entities[what_pred], entities[where_pred]])\n",
    "    df_ranking = pd.DataFrame(data_list, columns=['predicate', 'whom', 'subject', 'why', 'what', 'where'])\n",
    "    df_attension = get_attention(questions)\n",
    "    \n",
    "    return df_ranking, df_attension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51885798",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def main_func01(_title, _victim_name, criminal, predicate, _last_index, _story_len):\n",
    "    from_ = f'{_title}:{_last_index-_story_len+1}'\n",
    "    to_ = f'{_title}:{_last_index}'\n",
    "    predicate = predicate\n",
    "    victim = f'{_title}:{_victim_name}'\n",
    "    criminal = f'{_title}:{criminal}'\n",
    "    df_ranking, df_attension = make_ranking(\n",
    "        from_, to_, predicate, victim, MASK_E, MASK_E, MASK_E, MASK_E)\n",
    "\n",
    "    pred_rank = df_ranking.index[df_ranking['subject']==criminal].tolist()\n",
    "    pred_rank = pred_rank[0] if len(pred_rank)==1 else -1\n",
    "    logger.info(f\"The pred ranking about {criminal} is {pred_rank}\")\n",
    "    display(df_ranking.iloc[:max(20, pred_rank)])\n",
    "    len_ = len(df_attension)\n",
    "    for i in range(len_-10, len_):\n",
    "        print(f\"index={i}, triple={df_attension.iloc[i,:3].tolist()}, attention list\")\n",
    "        display(df_attension.sort_values(f'atten_from{i}', ascending=False).iloc[:,[0,1,2,3+i]],)\n",
    "    return df_ranking, df_attension\n",
    "\n",
    "def check_killer(_title, _victim_name, _killer_name, _last_index, _story_len):\n",
    "    return main_func01(_title, _victim_name, _killer_name, KILL, _last_index, _story_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c482dd7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fe5d84",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 白銀\n",
    "Who took out the White Silver Blaze? (criminal & explanation) \n",
    "被害者: Silver_Blaze\n",
    "犯人: \n",
    "犯行動機:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4154837",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "victim = 'SilverBlaze:Silver_Blaze'\n",
    "df_ranking_SilverBlaze, df_attension_SilverBlaze = make_ranking(\n",
    "    'SilverBlaze:330', 'SilverBlaze:396', BRING, MASK_E, MASK_E, MASK_E, victim, MASK_E)\n",
    "\n",
    "display(df_ranking_SilverBlaze.iloc[:20,:])\n",
    "# display(df_attension_SpeckledBand)\n",
    "# ヒートマップの作成\n",
    "# sns.heatmap(df_atten.iloc[:,3:].iloc[:32,:32])\n",
    "len_ = len(df_attension_SilverBlaze)\n",
    "for i in range(len_-20, len_):\n",
    "    display(i, df_attension_SilverBlaze.iloc[i,:3].tolist())\n",
    "    display(df_attension_SilverBlaze.sort_values(f'atten_from{i}', ascending=False).iloc[:20,[0,1,2,3+i]])\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4ef63c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}