{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "from const.const_values import PROJECT_DIR\n",
    "os.chdir(PROJECT_DIR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training example"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To train the model, run \"src/run_for_KGC.py\".\n",
    "\n",
    "When executing the simulation, it is necessary to include model and training parameters as well as the storage location as arguments.\n",
    "\n",
    "Parameters can be checked with \"-h\"."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: run_for_KGC.py [-h] [--notebook] [--console-level {info,debug}]\r\n",
      "                      [--logfile LOGFILE] [--param-file PARAM_FILE]\r\n",
      "                      [--device-name {cpu,cuda,mps}] [--train-anyway]\r\n",
      "                      [--old-data OLD_DATA]\r\n",
      "                      [--tensorboard-dir TENSORBOARD_DIR]\r\n",
      "                      [--checkpoint-dir CHECKPOINT_DIR] --model-path\r\n",
      "                      MODEL_PATH [--resume-from-checkpoint]\r\n",
      "                      [--resume-from-last-point]\r\n",
      "                      [--only-load-trainer-evaluator]\r\n",
      "                      [--resume-checkpoint-path RESUME_CHECKPOINT_PATH]\r\n",
      "                      [--pre-train] [--train-valid-test] [--only-train]\r\n",
      "                      [--use-for-challenge100] [--use-for-challenge090]\r\n",
      "                      [--use-for-challenge075]\r\n",
      "                      [--use-title {ACaseOfIdentity,AbbeyGrange,CrookedMan,DancingMen,DevilsFoot,ResidentPatient,SilverBlaze,SpeckledBand}]\r\n",
      "                      [--do-optuna] [--optuna-file OPTUNA_FILE]\r\n",
      "                      [--study-name STUDY_NAME] [--n-trials N_TRIALS]\r\n",
      "                      [--story-special-num STORY_SPECIAL_NUM]\r\n",
      "                      [--relation-special-num RELATION_SPECIAL_NUM]\r\n",
      "                      [--entity-special-num ENTITY_SPECIAL_NUM]\r\n",
      "                      [--padding-token-e PADDING_TOKEN_E]\r\n",
      "                      [--cls-token-e CLS_TOKEN_E]\r\n",
      "                      [--mask-token-e MASK_TOKEN_E]\r\n",
      "                      [--sep-token-e SEP_TOKEN_E] [--bos-token-e BOS_TOKEN_E]\r\n",
      "                      [--padding-token-r PADDING_TOKEN_R]\r\n",
      "                      [--cls-token-r CLS_TOKEN_R]\r\n",
      "                      [--mask-token-r MASK_TOKEN_R]\r\n",
      "                      [--sep-token-r SEP_TOKEN_R] [--bos-token-r BOS_TOKEN_R]\r\n",
      "                      [--padding-token-s PADDING_TOKEN_S]\r\n",
      "                      [--cls-token-s CLS_TOKEN_S]\r\n",
      "                      [--mask-token-s MASK_TOKEN_S]\r\n",
      "                      [--sep-token-s SEP_TOKEN_S] [--bos-token-s BOS_TOKEN_S]\r\n",
      "                      [--model-version {01,02,03,03a}]\r\n",
      "                      [--embedding-dim EMBEDDING_DIM]\r\n",
      "                      [--entity-embedding-dim ENTITY_EMBEDDING_DIM]\r\n",
      "                      [--relation-embedding-dim RELATION_EMBEDDING_DIM]\r\n",
      "                      [--separate-head-and-tail] [--batch-size BATCH_SIZE]\r\n",
      "                      [--max-len MAX-LENGTH] [--no-use-pe]\r\n",
      "                      [--init-embedding-using-bert] [--mask-percent mask-rate]\r\n",
      "                      [--mask-mask-percent mask-rate]\r\n",
      "                      [--mask-random-percent random-rate]\r\n",
      "                      [--mask-nomask-percent nomask-rate] [--nhead N]\r\n",
      "                      [--num-layers NUM] [--dim-feedforward DIM]\r\n",
      "                      [--transformer-drop DROP_RATE]\r\n",
      "                      [--position-encoder-drop DROP_RATE] [--lr LR]\r\n",
      "                      [--lr-story LR_STORY] [--lr-relation LR_RELATION]\r\n",
      "                      [--lr-entity LR_ENTITY]\r\n",
      "                      [--loss-function {cross_entropy_loss,focal_loss}]\r\n",
      "                      [--loss-weight-story LOSS_WEIGHT_STORY]\r\n",
      "                      [--loss-weight-relation LOSS_WEIGHT_RELATION]\r\n",
      "                      [--loss-weight-entity LOSS_WEIGHT_ENTITY]\r\n",
      "                      [--epoch EPOCH] [--early-stopping]\r\n",
      "                      [--early-stopping-count EARLY_STOPPING_COUNT]\r\n",
      "                      [--valid-interval VALID_INTERVAL] [--gamma GAMMA]\r\n",
      "\r\n",
      "This is make and training source code for KGC.\r\n",
      "\r\n",
      "options:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --notebook            if use notebook, use this argument.\r\n",
      "  --console-level {info,debug}\r\n",
      "                        log level on console\r\n",
      "  --logfile LOGFILE     the path of saving log\r\n",
      "  --param-file PARAM_FILE\r\n",
      "                        the path of saving param\r\n",
      "  --device-name {cpu,cuda,mps}\r\n",
      "                        cpu, cuda, mps\r\n",
      "  --train-anyway        It will not be reproducible, but it could be faster.\r\n",
      "  --old-data OLD_DATA   If you use old data, please enter the number.\r\n",
      "                        Basically, do not put anything in.\r\n",
      "\r\n",
      "dir and path:\r\n",
      "  There are the setting of training setting dir or path.\r\n",
      "\r\n",
      "  --tensorboard-dir TENSORBOARD_DIR\r\n",
      "                        tensorboard direction\r\n",
      "  --checkpoint-dir CHECKPOINT_DIR\r\n",
      "                        tensorboard direction\r\n",
      "  --model-path MODEL_PATH\r\n",
      "                        model path\r\n",
      "  --resume-from-checkpoint\r\n",
      "                        if use checkpoint, use this argument.\r\n",
      "  --resume-from-last-point\r\n",
      "                        if use checkpoint, use this argument.\r\n",
      "  --only-load-trainer-evaluator\r\n",
      "                        load only mode. not training. use it for valid model.\r\n",
      "  --resume-checkpoint-path RESUME_CHECKPOINT_PATH\r\n",
      "                        if use checkpoint, use this argument.\r\n",
      "\r\n",
      "use title setting:\r\n",
      "  There are the setting of training title.\r\n",
      "\r\n",
      "  --pre-train           Put on if you are doing pre-training\r\n",
      "  --train-valid-test\r\n",
      "  --only-train\r\n",
      "  --use-for-challenge100\r\n",
      "  --use-for-challenge090\r\n",
      "  --use-for-challenge075\r\n",
      "  --use-title {ACaseOfIdentity,AbbeyGrange,CrookedMan,DancingMen,DevilsFoot,ResidentPatient,SilverBlaze,SpeckledBand}\r\n",
      "                        ACaseOfIdentity or AbbeyGrange or CrookedMan or\r\n",
      "                        DancingMen or DevilsFoot or ResidentPatient or\r\n",
      "                        SilverBlaze or SpeckledBand\r\n",
      "\r\n",
      "optuna setting:\r\n",
      "  There are the setting of optuna.\r\n",
      "\r\n",
      "  --do-optuna           do optuna\r\n",
      "  --optuna-file OPTUNA_FILE\r\n",
      "                        optuna file\r\n",
      "  --study-name STUDY_NAME\r\n",
      "                        optuna study-name\r\n",
      "  --n-trials N_TRIALS   optuna n-trials\r\n",
      "\r\n",
      "special token setting:\r\n",
      "  There are the setting of special token.\r\n",
      "\r\n",
      "  --story-special-num STORY_SPECIAL_NUM\r\n",
      "                        story special num\r\n",
      "  --relation-special-num RELATION_SPECIAL_NUM\r\n",
      "                        relation special num\r\n",
      "  --entity-special-num ENTITY_SPECIAL_NUM\r\n",
      "                        entity special num\r\n",
      "\r\n",
      "special (tail) embedding token setting:\r\n",
      "  There are the setting of special (tail) embedding token setting.\r\n",
      "\r\n",
      "  --padding-token-e PADDING_TOKEN_E\r\n",
      "                        padding\r\n",
      "  --cls-token-e CLS_TOKEN_E\r\n",
      "                        cls\r\n",
      "  --mask-token-e MASK_TOKEN_E\r\n",
      "                        mask\r\n",
      "  --sep-token-e SEP_TOKEN_E\r\n",
      "                        sep\r\n",
      "  --bos-token-e BOS_TOKEN_E\r\n",
      "                        bos\r\n",
      "\r\n",
      "special (tail) embedding token setting:\r\n",
      "  There are the setting of special relation embedding token setting.\r\n",
      "\r\n",
      "  --padding-token-r PADDING_TOKEN_R\r\n",
      "                        padding\r\n",
      "  --cls-token-r CLS_TOKEN_R\r\n",
      "                        cls\r\n",
      "  --mask-token-r MASK_TOKEN_R\r\n",
      "                        mask\r\n",
      "  --sep-token-r SEP_TOKEN_R\r\n",
      "                        sep\r\n",
      "  --bos-token-r BOS_TOKEN_R\r\n",
      "                        bos\r\n",
      "\r\n",
      "special (tail) embedding token setting:\r\n",
      "  There are the setting of special (head) embedding token setting.\r\n",
      "\r\n",
      "  --padding-token-s PADDING_TOKEN_S\r\n",
      "                        padding\r\n",
      "  --cls-token-s CLS_TOKEN_S\r\n",
      "                        cls\r\n",
      "  --mask-token-s MASK_TOKEN_S\r\n",
      "                        mask\r\n",
      "  --sep-token-s SEP_TOKEN_S\r\n",
      "                        sep\r\n",
      "  --bos-token-s BOS_TOKEN_S\r\n",
      "                        bos\r\n",
      "\r\n",
      "model setting:\r\n",
      "  There are the setting of model params.\r\n",
      "\r\n",
      "  --model-version {01,02,03,03a}\r\n",
      "                        model version.\r\n",
      "  --embedding-dim EMBEDDING_DIM\r\n",
      "                        The embedding dimension. Default: 128\r\n",
      "  --entity-embedding-dim ENTITY_EMBEDDING_DIM\r\n",
      "                        The embedding dimension. Default: 128\r\n",
      "  --relation-embedding-dim RELATION_EMBEDDING_DIM\r\n",
      "                        The embedding dimension. Default: 128\r\n",
      "  --separate-head-and-tail\r\n",
      "                        If True, it head Embedding and tail Embedding are\r\n",
      "                        different.\r\n",
      "  --batch-size BATCH_SIZE\r\n",
      "                        batch size\r\n",
      "  --max-len MAX-LENGTH  max length of 1 batch. default: 256\r\n",
      "  --no-use-pe           to check pe(position encoding) power, we have to make\r\n",
      "                        no pe model\r\n",
      "  --init-embedding-using-bert\r\n",
      "                        if it is set and the model is 03a, it will be pre_init\r\n",
      "                        by bert\r\n",
      "\r\n",
      "model setting of mask-percent:\r\n",
      "  MUST mask-mask + mask-random + mask-nomask == 1.00.\r\n",
      "\r\n",
      "  --mask-percent mask-rate\r\n",
      "                        default: 0.15\r\n",
      "  --mask-mask-percent mask-rate\r\n",
      "                        default: 0.80\r\n",
      "  --mask-random-percent random-rate\r\n",
      "                        default: 0.10\r\n",
      "  --mask-nomask-percent nomask-rate\r\n",
      "                        default: 0.10\r\n",
      "\r\n",
      "model setting of transformer:\r\n",
      "  There are the setting of transformer params in model.\r\n",
      "\r\n",
      "  --nhead N             nhead. Default: 4.\r\n",
      "  --num-layers NUM      num layers. Default: 4.\r\n",
      "  --dim-feedforward DIM\r\n",
      "                        dim of feedforward. Default: 1028.\r\n",
      "  --transformer-drop DROP_RATE\r\n",
      "                        transformer-drop. Default: 0.1.\r\n",
      "  --position-encoder-drop DROP_RATE\r\n",
      "                        position-encoder-drop. Default: 0.1.\r\n",
      "\r\n",
      "model optimizer setting:\r\n",
      "  There are the setting of model optimizer params.\r\n",
      "\r\n",
      "  --lr LR               learning rate (default: 0.003)\r\n",
      "  --lr-story LR_STORY   learning rate (default: same as --lr)\r\n",
      "  --lr-relation LR_RELATION\r\n",
      "                        learning rate (default: same as --lr)\r\n",
      "  --lr-entity LR_ENTITY\r\n",
      "                        learning rate (default: same as --lr)\r\n",
      "  --loss-function {cross_entropy_loss,focal_loss}\r\n",
      "                        loss function (default: CrossEntropyLoss)\r\n",
      "  --loss-weight-story LOSS_WEIGHT_STORY\r\n",
      "                        loss-weight-story\r\n",
      "  --loss-weight-relation LOSS_WEIGHT_RELATION\r\n",
      "                        loss-weight-relation\r\n",
      "  --loss-weight-entity LOSS_WEIGHT_ENTITY\r\n",
      "                        loss-weight-entity\r\n",
      "  --epoch EPOCH         max epoch\r\n",
      "  --early-stopping\r\n",
      "  --early-stopping-count EARLY_STOPPING_COUNT\r\n",
      "  --valid-interval VALID_INTERVAL\r\n",
      "                        valid-interval\r\n",
      "\r\n",
      "focal loss setting:\r\n",
      "  There are the setting of focal loss.\r\n",
      "\r\n",
      "  --gamma GAMMA         gamma\r\n"
     ]
    }
   ],
   "source": [
    "!python src/run_for_KGC.py -h"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## for example"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python3 src/run_for_KGC.py   \\\n",
    "\t--device cuda --console-level info --pre-train --model-version 03 \\\n",
    "\t--only-train --epoch ${Epoch} --batch-size 256 \\\n",
    "\t--logfile ${Logfile}/log.log --tensorboard-dir ${Logfile}/tensorboard \\\n",
    "\t--param-file ${Logfile}/param.pkl --model-path ${Logfile}/model.pth \\\n",
    "\t--checkpoint-dir ${Logfile}/checkpoint/ \\\n",
    "\t--max-len 512 \\\n",
    "\t--embedding-dim ${EmbeddingDim} --entity-embedding-dim ${EEmbeddingDim} --relation-embedding-dim ${REmbeddingDim} \\\n",
    "\t--lr ${Lr} --lr-story ${LrStory} --lr-relation ${LrRelation} --lr-entity ${LREntity} \\\n",
    "\t--loss-function ${LossFunction} \\\n",
    "\t--mask-percent ${MaskPercent} --mask-mask-percent ${MaskMaskPercent} \\\n",
    "\t--mask-random-percent ${MaskRandomPercent} --mask-nomask-percent ${MaskNomaskPercent} \\\n",
    "\t--valid-interval 10000 ${@:2}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The training time for this model is long.\n",
    "\n",
    "The experiment with this parameter takes about 3 hours using the GPU."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After training, the model is saved. The parameters are also automatically saved when you move the file.\n",
    "\n",
    "Today, we will verify the model using the saved model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}