{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b2dca8",
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "# ========== python ==========\n",
    "import os\n",
    "from logging import Logger\n",
    "from pathlib import Path\n",
    "import gc\n",
    "# noinspection PyUnresolvedReferences\n",
    "from typing import List, Dict, Tuple, Optional, Union, Callable, Final, Literal, get_args\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "PROJECT_DIR = Path().resolve().parents[1]\n",
    "os.chdir(PROJECT_DIR)\n",
    "SEED: Final = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d6167a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.setup import load_param, easy_logger, get_device\n",
    "from utils.torch import load_model, torch_fix_seed\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from ignite.handlers import Checkpoint\n",
    "from run_for_KGC import main_function\n",
    "logger = easy_logger('log/test.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd075bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = load_param('saved_models/kgc/SilverBlaze090/03/param.pkl')\n",
    "device = get_device(device_name='cpu', logger=logger)\n",
    "# args.pre_train = True\n",
    "args.logger = logger\n",
    "args.device = device\n",
    "args.batch_size = 1\n",
    "args.max_len=512\n",
    "args.tensorboard_dir=None\n",
    "args.only_load_trainer_evaluator=True\n",
    "args.pre_train=False\n",
    "del args.optuna_file, args.device_name, args.pid\n",
    "del args.study_name, args.n_trials\n",
    "logger.info(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6300cb9",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "torch_fix_seed(seed=SEED)\n",
    "model, data_dict = main_function(args, logger=logger)\n",
    "encoder_last_layer = model.transformer.layers[-1]\n",
    "model.eval()\n",
    "dataset_train, dataset_valid, dataset_test = data_dict['datasets']\n",
    "triple = dataset_train.triple\n",
    "data_helper = data_dict['data_helper']\n",
    "evaluator = data_dict['train_items']['evaluator']\n",
    "load_model(model, args.model_path, device)\n",
    "print(len(data_helper.processed_train_triple), len(triple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590e2ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_for_KGC import get_all_tokens\n",
    "to_token = \"{}\".format\n",
    "PAD_E = to_token(\"pad_e\")\n",
    "CLS_E = to_token('cls_e')\n",
    "MASK_E: Final[str] = to_token('mask_e')\n",
    "SEP_E: Final[str] = to_token('sep_e')\n",
    "BOS_E: Final[str] = to_token('bos_e')\n",
    "PAD_R: Final[str] = to_token('pad_r')\n",
    "CLS_R: Final[str] = to_token('cls_r')\n",
    "MASK_R: Final[str] = to_token('mask_r')\n",
    "SEP_R: Final[str] = to_token('sep_r')\n",
    "BOS_R: Final[str] = to_token('bos_r')\n",
    "\n",
    "((pad_token_e, pad_token_r), (cls_token_e, cls_token_r), (mask_token_e, mask_token_r),\n",
    "     (sep_token_e, sep_token_r), (bos_token_e, bos_token_r)) = get_all_tokens(args)\n",
    "\n",
    "data_helper.set_special_names(\n",
    "    index2name_entity={pad_token_e: PAD_E, cls_token_e: CLS_E, mask_token_e: MASK_E, sep_token_e: SEP_E, bos_token_e: BOS_E},\n",
    "    index2name_relation={pad_token_r: PAD_R, cls_token_r: CLS_R, mask_token_r: MASK_R, sep_token_r: SEP_R, bos_token_r: BOS_R},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ec807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = data_helper.processed_entities\n",
    "d_e = {e: i for i, e in enumerate(entities)}\n",
    "relations = data_helper.processed_relations\n",
    "d_r = {r: i for i, r in enumerate(relations)}\n",
    "triple_df = pd.DataFrame([(entities[_t[0]], relations[_t[1]], entities[_t[2]]) for _t in triple], columns=['head', 'relation', 'tail']) \n",
    "# story_entities = triple_df\n",
    "# triple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3573be3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(model, target, inputs):\n",
    "    feature = None\n",
    "\n",
    "    def forward_hook(module, inputs, _):\n",
    "        # 順伝搬の出力を features というグローバル変数に記録する\n",
    "        global features\n",
    "        # 1. detach でグラフから切り離す。\n",
    "        # 2. clone() でテンソルを複製する。モデルのレイヤーで ReLU(inplace=True) のように\n",
    "        #    inplace で行う層があると、値がその後のレイヤーで書き換えられてまい、\n",
    "        #    指定した層の出力が取得できない可能性があるため、clone() が必要。\n",
    "        x, _, _ = inputs\n",
    "        outputs = module.forward(x, x, x, need_weights=True)[1]\n",
    "        features = outputs.detach().clone()\n",
    "\n",
    "    # コールバック関数を登録する。\n",
    "    handle = target.register_forward_hook(forward_hook)\n",
    "\n",
    "    # 推論する\n",
    "    model.eval()\n",
    "    model(inputs, torch.LongTensor([[]]), torch.LongTensor([[]]), torch.LongTensor([[]]))\n",
    "\n",
    "    # コールバック関数を解除する。\n",
    "    handle.remove()\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d654742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_(index):\n",
    "    input_ = dataset[index]\n",
    "    # display([(i, entities[h], relations[r], entities[t]) for i, (h, r, t) in enumerate(input_)])\n",
    "    features = extract(model, encoder_last_layer.self_attn, dataset[0][None, :])[0]\n",
    "    df_atten = pd.DataFrame([[entities[h], relations[r], entities[t]]+[features[j, i].item() for j in range(len(features))] for i, (h, r, t) in enumerate(input_)])\n",
    "    df_atten.columns=['head', 'relation', 'tail',] + [f'atten_from{i}' for i in range(len(df_atten.columns)-3)]\n",
    "    display(df_atten)\n",
    "    # ヒートマップの作成\n",
    "    # sns.heatmap(df_atten.iloc[:,3:].iloc[:32,:32])\n",
    "    for i in range(len(df_atten)):\n",
    "        display(i, df_atten.iloc[i,:3].tolist())\n",
    "        display(df_atten.sort_values(f'atten_from{i}', ascending=False).iloc[:10,:3])\n",
    "        print(\"----------\")\n",
    "    plt.show()\n",
    "# heatmap_(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d5d7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_heatmap2_(input_):\n",
    "    assert len(input_) == 1\n",
    "    features = extract(model, encoder_last_layer.self_attn, input_)[0]\n",
    "    df_atten = pd.DataFrame([[entities[h], relations[r], entities[t]]+[features[j, i].item() for j in range(len(features))] for i, (h, r, t) in enumerate(input_[0])])\n",
    "    df_atten.columns=['head', 'relation', 'tail',] + [f'atten_from{i}' for i in range(len(df_atten.columns)-3)]\n",
    "    sns.heatmap(df_atten.iloc[:,3:])\n",
    "    plt.show()\n",
    "    return df_atten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e2ef9e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "story_entities = triple_df['head'].tolist()\n",
    "# print(story_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8832fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ranking(_from, _to, _predicate, _whom, _subject, _why, _what, _where):\n",
    "    if not (_from is None and _to is None):\n",
    "        _start_index = story_entities.index(_from)-1 \n",
    "        _end_index = len(story_entities) - story_entities[::-1].index(_to)\n",
    "    else: \n",
    "        _start_index = 0\n",
    "        _end_index = 0\n",
    "    question_ = torch.tensor(\n",
    "        [\n",
    "            [d_e['bos_e'],d_r['bos_r'],d_e['bos_e']],\n",
    "            [d_e['mask_e'],d_r['kgc:infoSource'],d_e['AllTitle:Holmes']],\n",
    "            [d_e['mask_e'],d_r['kgc:hasPredicate'],d_e[_predicate]],\n",
    "            [d_e['mask_e'],d_r['kgc:whom'],d_e[_whom]],\n",
    "            [d_e['mask_e'],d_r['kgc:subject'],d_e[_subject]],\n",
    "            [d_e['mask_e'],d_r['kgc:why'],d_e[_why]],\n",
    "            [d_e['mask_e'],d_r['kgc:what'],d_e[_what]],\n",
    "            [d_e['mask_e'],d_r['kgc:where'],d_e[_where]],\n",
    "        ]\n",
    "    )\n",
    "    mask_ = torch.tensor(\n",
    "        [\n",
    "            [False, False, False],\n",
    "            [True, False, True],\n",
    "            [True, False, True],\n",
    "            [True, False, True],\n",
    "            [True, False, True],\n",
    "            [True, False, True],\n",
    "            [True, False, True],\n",
    "            [True, False, True],\n",
    "        ]\n",
    "    )\n",
    "    questions = torch.cat([triple[_start_index: _end_index], question_], dim=0).unsqueeze(0)\n",
    "    masks = torch.cat([torch.zeros(_end_index-_start_index,3), mask_], dim=0).to(torch.bool).transpose(1,0).unsqueeze(0)\n",
    "    tmp = []\n",
    "    with torch.no_grad():\n",
    "        _, (story_pred, relation_pred, entity_pred) = model(questions, masks[:,0], masks[:,1], masks[:,2])\n",
    "        sorted_ = torch.argsort(entity_pred.to('cpu'), dim=1, descending=True)\n",
    "        for i in range(sorted_.shape[1]):\n",
    "            ans_= sorted_[:, i]\n",
    "            info_source_, predicate_, whom_, subj_, why_, what_, where_ = ans_\n",
    "            tmp.append([entities[predicate_], entities[whom_], entities[subj_], entities[why_], entities[what_], entities[where_]])\n",
    "    df_ranking = pd.DataFrame(tmp, columns=['predicate', 'whom', 'subject', 'why', 'what', 'where'])\n",
    "    df_attension = make_heatmap2_(questions)\n",
    "    return df_ranking, df_attension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cfe0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_E = 'mask_e'\n",
    "KILL = 'word.predicate:kill'\n",
    "TAKE = 'word.predicate:take'\n",
    "BRING = 'word.predicate:bring'\n",
    "DIE = 'word.predicate:die'\n",
    "HIDE = 'word.predicate:hide'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d86a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_func01(_title, _victim_name, _killer_name, _last_index, _story_len):\n",
    "    from_ = f'{_title}:{_last_index-_story_len+1}'\n",
    "    to_ = f'{_title}:{_last_index}'\n",
    "    victim = f'{_title}:{_victim_name}'\n",
    "    killer = f'{_title}:{_killer_name}'\n",
    "    df_ranking, df_attension = make_ranking(\n",
    "        from_, to_, KILL, victim, MASK_E, MASK_E, MASK_E, MASK_E)\n",
    "\n",
    "    print(f\"{killer}, ranking\", df_ranking.index[df_ranking['subject']==killer].tolist())\n",
    "    display(df_ranking.iloc[:20,:])\n",
    "    # display(df_attension_SpeckledBand)\n",
    "    # ヒートマップの作成\n",
    "    # sns.heatmap(df_atten.iloc[:,3:].iloc[:32,:32])\n",
    "    len_ = len(df_attension)\n",
    "    for i in range(len_-20, len_):\n",
    "        display(i, df_attension.iloc[i,:3].tolist())\n",
    "        display(df_attension.sort_values(f'atten_from{i}', ascending=False).iloc[:20,[0,1,2,3+i]])\n",
    "        print(\"----------\")\n",
    "    return df_ranking, df_attension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1df7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_func01(_title, _victim_name, _killer_name, _last_index, _story_len):\n",
    "    from_ = f'{_title}:{_last_index-_story_len+1}'\n",
    "    to_ = f'{_title}:{_last_index}'\n",
    "    victim = f'{_title}:{_victim_name}'\n",
    "    killer = f'{_title}:{_killer_name}'\n",
    "    df_ranking, df_attension = make_ranking(\n",
    "        from_, to_, KILL, victim, MASK_E, MASK_E, MASK_E, MASK_E)\n",
    "\n",
    "    print(f\"{killer}, ranking\", df_ranking.index[df_ranking['subject']==killer].tolist())\n",
    "    display(df_ranking.iloc[:20,:])\n",
    "    # display(df_attension_SpeckledBand)\n",
    "    # ヒートマップの作成\n",
    "    # sns.heatmap(df_atten.iloc[:,3:].iloc[:32,:32])\n",
    "    len_ = len(df_attension)\n",
    "    for i in range(len_-20, len_):\n",
    "        display(i, df_attension.iloc[i,:3].tolist())\n",
    "        display(df_attension.sort_values(f'atten_from{i}', ascending=False).iloc[:20,[0,1,2,3+i]])\n",
    "        print(\"----------\")\n",
    "    return df_ranking, df_attension"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d210aba",
   "metadata": {},
   "source": [
    "### 白銀\n",
    "Who took out the White Silver Blaze? (criminal & explanation) \n",
    "被害者: Silver_Blaze\n",
    "犯人: \n",
    "犯行動機: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57400fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "victim = 'SilverBlaze:Silver_Blaze'\n",
    "df_ranking_SilverBlaze, df_attension_SilverBlaze = make_ranking(\n",
    "    f'SilverBlaze:{357-80+1}', 'SilverBlaze:357', BRING, MASK_E, MASK_E, MASK_E, victim, MASK_E)\n",
    "\n",
    "display(df_ranking_SilverBlaze.iloc[:20,:])\n",
    "# display(df_attension_SpeckledBand)\n",
    "# ヒートマップの作成\n",
    "# sns.heatmap(df_atten.iloc[:,3:].iloc[:32,:32])\n",
    "len_ = len(df_attension_SilverBlaze)\n",
    "for i in range(len_-20, len_):\n",
    "    display(i, df_attension_SilverBlaze.iloc[i,:3].tolist())\n",
    "    display(df_attension_SilverBlaze.sort_values(f'atten_from{i}', ascending=False).iloc[:20,[0,1,2,3+i]])\n",
    "    print(\"----------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
